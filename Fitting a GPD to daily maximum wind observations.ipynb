{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Fitting a Generalised Pareto Distribution to daily maximum wind observations\n",
    "\n",
    "This notebook presents a translation of the work of Sanabria & Cechet (2007) into Python. Why? Because I wanted to reproduce the results and generate more athstetically-pleasing graphics, which I don't have the confidence/skills to do in R. Here, I make use of the [seaborn](http://stanford.edu/~mwaskom/software/seaborn/index.html> \"seaborn: statistical data visualization\") package to take care of the plotting styles, letting me focus on ensuring the algorithm works correctly. \n",
    "\n",
    "For a detailed background on the algorithm, see Sanabria and Cechet's report [here](http://www.ga.gov.au/corporate_data/65052/Rec2007_012.pdf \"A Statistical Model of Severe Winds, Geoscience Australia Record 2007/012\").\n",
    "\n",
    "### Data\n",
    "The data used are observed daily maximum wind gust speeds from Bureau of Meteorology weather stations across Australia. GA has two collections if this data - one obtained in 2006 and another in 2012. The latter contains stations only in northern parts of the country, while the former has stations right across the country. The only key difference is that the 2006 data is reported in metres/second, the 2012 data in km/h. For some locations, there's barely a year of observations (e.g. some comparison sites), while the longest record is \n",
    "\n",
    "Each station record has a quality flag, that indicates whether the observation has been checked or not, and if the check flagged the observation as suspect, wrong or inconsistent with other observations. We use this flag to filter out all those suspect, wrong or inconsistent observations. \n",
    "\n",
    "\n",
    "### The Generalised Pareto Distribution\n",
    "The Generalised Pareto Distribution (GPD) is defined as:\n",
    "\n",
    "$H(y) = 1 - (1 + \\xi y / \\check{s}) ^{-1/\\xi}$\n",
    "\n",
    "where $\\check{s} = \\sigma + \\xi(u - \\mu)$ and $u = $ threshold value. $\\sigma$ and $\\mu$ are the scale and location parameters of a corresponding GEV distribution. If the data can be fitted to a GEV distribution, then values above the threshold can be fitted with a GPD.\n",
    "\n",
    "The fitted parameters are highly sensitive to the choice of threshold. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import division\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from functools import wraps\n",
    "import time\n",
    "import os\n",
    "from os.path import join as pjoin\n",
    "\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import genpareto\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.nonparametric.kde import KDEUnivariate\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "\n",
    "from return_period import returnLevels, empiricalReturnPeriod, returnPeriodUncertainty\n",
    "from distributions import fittedPDF\n",
    "\n",
    "from IPython.html.widgets import interact, fixed\n",
    "from IPython.html import widgets\n",
    "\n",
    "sns.set_context(\"poster\")\n",
    "sns.set_style(\"ticks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some helper functions to parse the input data and time function calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse(yr, month, day, time):\n",
    "    \"\"\"\n",
    "    Parse year, month and day as strings and return a datetime.\n",
    "    \n",
    "    Handles the case of a missing time string (Pandas returns nan \n",
    "    if the field is empty).\n",
    "    \"\"\"\n",
    "    if time is np.nan:\n",
    "        time='0000'\n",
    "    timestr = '{0}-{1}-{2} {3}'.format(yr, month, day, time)\n",
    "    \n",
    "    return datetime.strptime(timestr, '%Y-%m-%d %H%M')\n",
    "\n",
    "def timer(func):\n",
    "    \"\"\"\n",
    "    Decorator to report execution time of a function/script.\n",
    "    \"\"\"\n",
    "    @wraps(func)\n",
    "    def wrap(*args, **kwargs):\n",
    "        t1 = time.time()\n",
    "        res = func(*args, **kwargs)\n",
    "\n",
    "        tottime = time.time() - t1\n",
    "        msg = \"%02d:%02d:%02d \" % \\\n",
    "          reduce(lambda ll, b : divmod(ll[0], b) + ll[1:],\n",
    "                        [(tottime,), 60, 60])\n",
    "\n",
    "        print \"Time for {0}: {1}\".format(func.func_name, msg) \n",
    "        return res\n",
    "\n",
    "    return wrap\n",
    "\n",
    "def find_nearest_index(array, value):\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return idx\n",
    "\n",
    "def calculateShape(mu, data):\n",
    "    \"\"\"\n",
    "    :param float mu: threshold parameter for the GPD distribution.\n",
    "    :param data: :class:`numpy.ndarray` of data values to fit.\n",
    "    \"\"\"\n",
    "    nobs = len(data)\n",
    "    nexc = len(data[data > mu])\n",
    "    rate = float(nexc)/float(nobs)\n",
    "    gpd = genpareto.fit(data[data > mu] - mu)\n",
    "\n",
    "    return gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define plotting routines to display the results of the fitting process. \n",
    "\n",
    "The diagnostics plot has a probability-probability plot, a quantile-quantile plot (both comparing empirical probabilities/quantiles with model values), a return level plot that has both the fitted model and empirical return periods and a density plot. \n",
    "\n",
    "The return level plot presents the return period curve of the fitted model and the empirical return periods. A 90% confidence interval is also plotted, based on the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotDiagnostics(data, mu, xi, sigma):\n",
    "    \"\"\"\n",
    "    Create a 4-panel diagnostics plot of the fitted distribution.\n",
    "\n",
    "    :param data: :class:`numpy.ndarray` of observed data values (in units\n",
    "                 of metres/second).\n",
    "    :param float mu: Selected threshold value.\n",
    "    :param float xi: Fitted shape parameter.\n",
    "    :param float sigma: Fitted scale parameter.\n",
    "\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(2, 2)\n",
    "    axes = ax.flatten()\n",
    "    # Probability plots\n",
    "    sortedmax = np.sort(data[data > mu])   \n",
    "    gpdf = fittedPDF(data, mu, xi, sigma)\n",
    "    pp_x = sm.ProbPlot(sortedmax)\n",
    "    pp_x.ppplot(xlabel=\"Empirical\", ylabel=\"Model\", ax=axes[0], line='45')\n",
    "    axes[0].set_title(\"Probability plot\")\n",
    "\n",
    "    prplot = sm.ProbPlot(sortedmax, genpareto, distargs=(xi,),\n",
    "                         loc=mu, scale=sigma)\n",
    "    prplot.qqplot(xlabel=\"Model\", ylabel=\"Empirical\", ax=axes[1], line='45')\n",
    "    axes[1].set_title(\"Quantile plot\")\n",
    "\n",
    "    ax2 = axes[2]\n",
    "    rp = np.array([1, 2, 5, 10, 20, 50, 100, 200,\n",
    "                   500, 1000, 2000, 5000, 10000])\n",
    "    rate = float(len(sortedmax)) / float(len(data))\n",
    "    rval = returnLevels(rp, mu, xi, sigma, rate)\n",
    "\n",
    "    emprp = empiricalReturnPeriod(np.sort(data))\n",
    "    ax2.semilogx(rp, rval, label=\"Fitted RP curve\", color='r')\n",
    "    ax2.scatter(emprp[emprp > 1], np.sort(data)[emprp > 1],\n",
    "                color='b', label=\"Empirical RP\", s=100)\n",
    "    ax2.legend(loc=2)\n",
    "    ax2.set_xlabel(\"Return period\")\n",
    "    ax2.set_ylabel(\"Return level\")\n",
    "    ax2.set_title(\"Return level plot\")\n",
    "    ax2.grid(True)\n",
    "    maxbin = 4 * np.ceil(np.floor(data.max() / 4) + 1)\n",
    "    sns.distplot(sortedmax, bins=np.arange(mu, maxbin, 2),\n",
    "                 hist=True, axlabel='Wind speed (m/s)',\n",
    "                 ax=axes[3])\n",
    "    axes[3].plot(sortedmax, gpdf, color='r')\n",
    "    axes[3].set_title(\"Density plot\")\n",
    "    plt.tight_layout()\n",
    "    \n",
    "def plotFit(data, mu, xi, sigma, title):\n",
    "    \"\"\"\n",
    "    Plot a fitted distribution, with approximate 90% confidence interval\n",
    "    and empirical return period values.\n",
    "\n",
    "    :param data: :class:`numpy.ndarray` of observed data values.\n",
    "    :param float mu: Selected threshold value.\n",
    "    :param float xi: Fitted shape parameter.\n",
    "    :param float sigma: Fitted scale parameter.\n",
    "    :param str title: Title string for the plot.\n",
    "    :param str figfile: Path to store the file (includes image format)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    rp = np.array([1, 2, 5, 10, 20, 50, 100, 200,\n",
    "                   500, 1000, 2000, 5000, 10000])\n",
    "    rate = float(len(data[data > mu])) / float(len(data))\n",
    "    rval = returnLevels(rp, mu, xi, sigma, rate)\n",
    "\n",
    "    emprp = empiricalReturnPeriod(data)\n",
    "    #err = returnPeriodUncertainty(data, mu, xi, sigma, rp)\n",
    "\n",
    "    sortedmax = np.sort(data)\n",
    "    fig, ax1 = plt.subplots(1, 1)\n",
    "    ax1.semilogx(rp, rval, label=\"Fitted RP curve\")\n",
    "    print rp\n",
    "    print rval\n",
    "    #ax1.semilogx(rp, rval + 1.96 * err, label=\"90% CI\",\n",
    "    #             linestyle='--', color='0.5')\n",
    "    #ax1.semilogx(rp, rval - 1.96 * err, linestyle='--', color='0.5')\n",
    "\n",
    "    ax1.scatter(emprp[emprp > 1], sortedmax[emprp > 1], s=100,\n",
    "                color='r', label=\"Empirical RP\")\n",
    "\n",
    "    title_str = (title + \"\\n\" +\n",
    "                 r\"$\\mu$ = {0:.3f}, $\\xi$ = {1:.5f}, $\\sigma$ = {2:.4f}\".\n",
    "                 format(mu, xi, sigma))\n",
    "    ax1.set_title(title_str)\n",
    "    ax1.legend(loc=2)\n",
    "    ax1.set_ylim((0, 100))\n",
    "    ax1.set_xlim((1, 10000))\n",
    "    ax1.set_ylabel('Wind speed (m/s)')\n",
    "    ax1.set_xlabel('Return period (years)')\n",
    "    ax1.grid(which='major')\n",
    "    ax1.grid(which='minor', linestyle='--', linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NAMES = ['dc', 'StnNum', 'Year', 'Month', 'Day', 'Speed', \n",
    "         'QSpeed', 'Dir', 'QDir', 'Time', 'QTime']\n",
    "CONVERT = {'Speed': lambda s: float(s or 0)}\n",
    "stations = [\"4032\", \"8051\", \"14040\", \"14161\", \"14508\", \"31011\", \"40214\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_path = 'C:\\\\WorkSpace\\\\data\\\\daily\\\\input\\\\'\n",
    "#basename = \"DC02D_Data_{0:06d}_999999997960863.txt\"\n",
    "basename = \"DC02D_Data_{0:06d}_99999999720437.txt\"\n",
    "stnNum = \"14015\"\n",
    "stnName = \"Darwin Airport\"\n",
    "\n",
    "fname = pjoin(input_path, basename.format(int(stnNum)))\n",
    "if os.path.exists(fname):\n",
    "    df = pd.read_csv(fname, skipinitialspace=True, skiprows=1, names=NAMES, \n",
    "                     parse_dates=[['Year', 'Month', 'Day', 'Time']], \n",
    "                     date_parser=parse, index_col=False, converters=CONVERT)\n",
    "    df.describe()\n",
    "else:\n",
    "    print \"{0} does not exist\".format(fname)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the daily values as a time series for a quick visual check of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.title('Daily maximum wind speeds for {0}'.format(stnName))\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Wind speed (m/s)')\n",
    "x = [idx for idx in df.Year_Month_Day_Time]\n",
    "y = df.Speed\n",
    "plt.plot(x,y)\n",
    "plt.axhline(np.median(y), linestyle='--', lw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the observations to exclude null values (i.e. missing records) and those that do not meet the quality criteria. The data come with quality flags that indicate suspicious, wrong or inconsistent (with other observations) records, and we eliminate those from the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "quality = df['QSpeed'].fillna(\"X\").map(lambda x: x in ['Y','N','X',' ', np.nan])\n",
    "dmax = df['Speed'][df['Speed'].notnull() & quality]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the challenging part of the process - selecting an appropriate threshold value for the GPD. For this, I use the symbol $\\mu$ to represent the threshold value - note the different definition to that at the start. This is more for my convenience to use the Greek letters for the GPD parameters (essentially, the threshold is used as the location parameter in scipy-speak).  \n",
    "\n",
    "The process steps through all values of $\\mu$ from the median to the maximum observed wind speed. Each value of $\\mu$ is fitted to a GPD, using only the exceedances $v_i - \\mu$. If the number of exceedances is less than 10, that threshold value is discarded.\n",
    "\n",
    "The fitting routine returns the shape and scale parameter, and only those with a shape parameter $\\xi < \\varepsilon$ are retained, where $\\varepsilon = -0.01$. The corresponding quantiles for 1000 and 10000 years ($q_{1000}$ and $q_{10000}$) are calculated. A large difference between these quantiles is indicative of numerical stability problems when calculating large quantiles ($years > 10000$). If $q_{10000} - q_{1000} > 0.12\\times q_{10000}$, then the threshold value is discarded.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@timer\n",
    "def selectThreshold(data):\n",
    "    \"\"\"\n",
    "    Select an appropriate threshold for fitting a generalised pareto\n",
    "    distribution. \n",
    "    \n",
    "    The only constraint placed on the selection is that the shape \n",
    "    parameter is negative (such that the distribution is bounded).\n",
    "    \n",
    "    :param data: :class:`numpy.ndarray` containing the observed values (with \n",
    "                 missing values removed).\n",
    "    :returns: tuple of the shape, scale and threshold.\n",
    "    \"\"\"\n",
    "    \n",
    "    sh = []\n",
    "    sc = []\n",
    "    t = []\n",
    "    q1000list = []\n",
    "    q10000list = []\n",
    "    \n",
    "    eps = -0.01\n",
    "    datamax = data.max()\n",
    "    nobs = len(data)\n",
    "    for mu in np.arange(np.median(data), datamax, 0.005):\n",
    "        nexc = len(data[data > mu]) \n",
    "        rate = nexc / nobs\n",
    "        if nexc < 5:\n",
    "            break\n",
    "\n",
    "        pp = calculateShape(mu, data)\n",
    "        q1000, q10000 = returnLevels(np.array([1000, 10000]), mu, pp[0], pp[2], rate)\n",
    "        if np.isnan(q1000):\n",
    "            continue\n",
    "\n",
    "        if np.isnan(q10000):\n",
    "            continue\n",
    "\n",
    "        qdiff = np.abs(q10000 - q1000)\n",
    "        if pp[0] < eps and qdiff < 0.12*q10000 and qdiff > -eps: \n",
    "            t.append(mu)\n",
    "            sh.append(pp[0])\n",
    "            sc.append(pp[2])\n",
    "            q1000list.append(q1000)\n",
    "            q10000list.append(q10000)\n",
    "            \n",
    "    if len(t) == 0:\n",
    "        print \"No suitable shape parameters identified\"\n",
    "        return 0, 0, 0\n",
    "    Av1000 = np.mean(np.array(q1000list))\n",
    "    Av10000 = np.mean(np.array(q10000list))\n",
    "    Av1000 = np.ceil(Av1000 + 0.05*Av1000)\n",
    "    Av10000 = np.ceil(Av10000 + 0.05*Av10000)\n",
    "\n",
    "    idx1000 = find_nearest_index(np.array(q1000list), Av1000)\n",
    "    idx10000 = find_nearest_index(np.array(q10000list), Av10000)\n",
    "    \n",
    "    u1000 = t[idx1000]\n",
    "    u10000 = t[idx10000]\n",
    "\n",
    "    if u1000 > u10000:\n",
    "        shmax = sh[idx1000]\n",
    "        scmax = sc[idx1000]\n",
    "    else:\n",
    "        shmax = sh[idx10000]\n",
    "        scmax = sc[idx10000]\n",
    "\n",
    "    return shmax, scmax, u1000    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@timer\n",
    "def selThreshold(dmax):\n",
    "    \"\"\"\n",
    "    Select the best fitting threshold that maximises the return period values, but minimises the $R^$ value\n",
    "    when fitted against the observed distribution.\n",
    "    \"\"\"\n",
    "    eps = -0.01\n",
    "    datamax = data.max()\n",
    "    nobs = len(data)\n",
    "    mu = np.median(data)\n",
    "    while mu < datamax:\n",
    "        nexc = len(data[data > mu])\n",
    "        exceed = data[data > mu]\n",
    "        rate = nexc / nobs\n",
    "        if nexc < 10:\n",
    "            break\n",
    "        pp = calculateShape(mu, data)\n",
    "        \n",
    "        if pp[0] > eps:\n",
    "            break\n",
    "            \n",
    "        emppdf = empiricalPDF(exceed)\n",
    "        \n",
    "        try:\n",
    "            popt, pcov = curve_fit(lambda x, xi, sigma: \\\n",
    "                                   genpareto.pdf(x, xi, loc=mu, scale=sigma),\n",
    "                                   np.sort(exceed), emppdf, (xi, sigma))\n",
    "        except RuntimeError as e:\n",
    "            return 0.\n",
    "        sd = np.sqrt(np.diag(pcov))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xi, sigma, mu = selectThreshold(dmax)\n",
    "print xi, sigma, mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plotFit(dmax, mu, xi, sigma, stnName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plotDiagnostics(dmax, mu, xi, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "npy = 365.25\n",
    "dmax = df['Speed'][df['Speed'].notnull()]\n",
    "nobs = len(dmax)\n",
    "sortedmax = np.sort(dmax)\n",
    "\n",
    "# Empirical return periods:\n",
    "emprp = 1./(1. - np.arange(1, nobs+1, 1)/(nobs + 1))/npy\n",
    "\n",
    "# Start with a threshold that is half the maximum observed value\n",
    "thresh = np.median(dmax) #dmax.max()/2.#sortedmax[RP2 > 1][0]\n",
    "nexc = len(dmax[dmax > thresh])\n",
    "rate = float(nexc)/float(nobs)\n",
    "\n",
    "pp = genpareto.fit(dmax[dmax > thresh] - thresh)\n",
    "npy = 365.25\n",
    "n = len(dmax)\n",
    "\n",
    "x = np.array([1, 2, 5, 10, 20, 50, 100, 200, 500, 1000, 2000, 5000, 10000])\n",
    "rpfit = returnLevels(x, thresh, pp[0], pp[2], rate)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\n",
    "\n",
    "# Bootstrap resampling:\n",
    "for i in range(100):\n",
    "    data = np.random.choice(dmax, nobs-1, replace=True)\n",
    "    sfit = genpareto.fit(data[data > thresh] - thresh)\n",
    "    #if sfit[0] < 0.0:\n",
    "    srp = returnLevels(x, thresh, sfit[0], sfit[2], rate)\n",
    "    ax1.semilogx(x, srp, alpha=0.1, color='0.5')\n",
    "    \n",
    "ax1.semilogx(x, rpfit, label=r\"$\\mu$={0:.2f} m/s\".format(thresh))\n",
    "ax1.semilogx(emprp[emprp > 1], sortedmax[emprp > 1], marker='x',\n",
    "             color='r',label=\"Empirical RP\")\n",
    "#plt.xscale('log')\n",
    "ax1.set_ylim((0, 100))\n",
    "ax1.set_xlim((1, 10000))\n",
    "ax1.set_ylabel('Wind speed (m/s)')\n",
    "ax1.set_xlabel('Return period (years)')\n",
    "ax1.legend()\n",
    "\n",
    "# Testing range of threshold values\n",
    "for t in np.arange(thresh, dmax.max(), 0.01):\n",
    "    trate = float(len(dmax[dmax > t]))/float(nobs)\n",
    "    tfit = genpareto.fit(dmax[dmax > t] - t)\n",
    "    if tfit[0] < 0.0:\n",
    "        trp = returnLevels(x, t, tfit[0], tfit[2], trate)\n",
    "        #if np.abs(trp[9] - trp[-1]) > 0.5:\n",
    "        ax2.semilogx(x, trp, alpha=0.1, color='0.5')\n",
    "        \n",
    "ax2.semilogx(x, rpfit)\n",
    "ax2.semilogx(emprp[emprp > 1], sortedmax[emprp > 1], marker='x', color='r')\n",
    "plt.xscale('log')\n",
    "ax2.set_ylim((0, 100))\n",
    "ax2.set_xlim((1, 10000))\n",
    "ax2.set_ylabel('Wind speed (m/s)')\n",
    "ax2.set_xlabel('Return period (years)')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_gpd(data, threshold):\n",
    "    ax = sns.distplot(data[data >= threshold], bins = np.arange(threshold, 250, 2.5),\n",
    "                     hist=True, fit=genpareto, axlabel='Wind speed (km/h)', \n",
    "                     kde_kws={'label':'KDE fit'},\n",
    "                     fit_kws={'label':'GPD fit',\n",
    "                              'color':'red'})\n",
    "    ax.legend()\n",
    "    params = genpareto.fit(data[data >= threshold], fscale=threshold)\n",
    "    print \"Fit parameters: \", params\n",
    "    print \"Crossing rate: \", float(len(dmax[dmax >= threshold]))/float(len(dmax))\n",
    "interact(plot_gpd, data=fixed(dmax), threshold=(0, 150., 1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
